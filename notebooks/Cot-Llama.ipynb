{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a59afd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-11T09:16:07.067302Z",
     "iopub.status.busy": "2024-10-11T09:16:07.066808Z",
     "iopub.status.idle": "2024-10-11T09:16:22.604107Z",
     "shell.execute_reply": "2024-10-11T09:16:22.602555Z"
    },
    "papermill": {
     "duration": 15.545523,
     "end_time": "2024-10-11T09:16:22.606957",
     "exception": false,
     "start_time": "2024-10-11T09:16:07.061434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\r\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.9.2)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\r\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: groq\r\n",
      "Successfully installed groq-0.11.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4dba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T09:16:22.617853Z",
     "iopub.status.busy": "2024-10-11T09:16:22.617443Z",
     "iopub.status.idle": "2024-10-11T09:42:33.702381Z",
     "shell.execute_reply": "2024-10-11T09:42:33.701233Z"
    },
    "papermill": {
     "duration": 1571.094086,
     "end_time": "2024-10-11T09:42:33.705395",
     "exception": false,
     "start_time": "2024-10-11T09:16:22.611309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import groq\n",
    "import time\n",
    "\n",
    "client = groq.Groq(api_key='<your groq api key>')\n",
    "\n",
    "def make_api_call(prompt):\n",
    "    \"\"\"This function makes an API call to Groq's model and returns the decision and CoT reasoning.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama3-8b-8192\",\n",
    "            messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"You are an expert AI assistant tasked with evaluating the completeness and thoroughness of a review. Your goal is to classify reviews as either 'Exhaustive' or 'Trivial' based on their coverage of key sections and aspects. Here are the definitions of the terms:\\n\\n\"\n",
    "\n",
    "                            \"1. **Exhaustive**: The review provides comprehensive feedback across multiple sections and aspects of the paper, offering detailed insight into key areas such as methodology, results, experiments, and more. A review should be classified as 'Exhaustive' if it covers a wide range of sections and aspects (e.g., Abstract, Introduction, Methodology, etc.) with depth, leaving no significant sections or questions unaddressed.\\n\\n\"\n",
    "\n",
    "                            \"2. **Trivial**: The review lacks depth and does not sufficiently cover critical sections or aspects. It might focus only on one or two areas (e.g., comments on Abstract or Introduction) and fails to address significant sections or aspects in detail. A 'Trivial' review might provide shallow or vague comments that do not contribute much to improving the paper.\\n\\n\"\n",
    "\n",
    "                            \"Here are the key sections and aspects you should be aware of:\\n\"\n",
    "                            \"Sections: Abstract (ABS), Introduction (INT), Related Works (RWK), Problem Definition/Idea (PDI), Data/Datasets (DAT), Methodology (MET), Experiments (EXP), Results (RES), Tables & Figures (TNF), Analysis (ANA), Future Work (FWK), Overall (OAL), Bibliography (BIB), External Knowledge (EXT).\\n\"\n",
    "                            \"Aspects: Appropriateness (APR), Originality/Novelty (NOV), Significance/Impact (IMP), Meaningful Comparison (CMP), Presentation/Formatting (PNF), Recommendation (REC), Empirical/Theoretical Soundness (EMP), Substance (SUB), Clarity (CLA).\\n\\n\"\n",
    "\n",
    "                            \"For example, a review that comments on several sections like 'Methodology,' 'Experiments,' and 'Results' in detail and provides constructive feedback on 'Originality,' 'Significance,' and 'Empirical Soundness' should be considered exhaustive. A review that only comments on the 'Introduction' or 'Abstract' without providing much insight into other sections should be considered trivial.\\n\\n\"\n",
    "\n",
    "                            \"### Important:\\n\"\n",
    "                            \"**Your decision MUST be directly supported by the step-by-step reasoning in the CoT (Chain of Thought).** \"\n",
    "                            \"Carefully evaluate each section and aspect mentioned in the CoT reasoning before making your final decision.\\n\\n\"\n",
    "\n",
    "                            \"### Double-Check:\\n\"\n",
    "                            \"Before you finalize your decision, ask yourself: 'Does the reasoning I've provided support an 'Exhaustive' or 'Trivial' decision?' \"\n",
    "                            \"Your decision **must align** with the CoT reasoning.\"\n",
    "                        )\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": (\n",
    "                            f\"{prompt}\\n\\n\"\n",
    "                            \"Evaluate the review's coverage of sections and aspects based on the reasoning provided. \"\n",
    "                            \"Please ensure the chain of thought reasoning is **step-wise**, following the Chain of Thought (CoT) reasoning process.\"\n",
    "                        )\n",
    "                    }\n",
    "                ],\n",
    "            max_tokens=8000,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        decision = \"Trivial\" if \"Trivial\" in result else \"Exhaustive\"\n",
    "        return decision, result\n",
    "    except Exception as e:\n",
    "        return \"Error\", str(e)\n",
    "\n",
    "def generate_prompt(group):\n",
    "    review_texts = ' '.join(group['review_text'].dropna())\n",
    "    section_coverage = ' '.join(group.filter(like='section_coverage').fillna('').agg(' '.join, axis=1))\n",
    "    aspect_coverage = ' '.join(group.filter(like='aspect_coverage').fillna('').agg(' '.join, axis=1))\n",
    "    return f\"Review Text: {review_texts} Section Coverage: {section_coverage} Aspect Coverage: {aspect_coverage}\"\n",
    "\n",
    "def annotate_dataset(df):\n",
    "    df['Decision'] = None\n",
    "    df['CoT_Reasoning'] = None\n",
    "\n",
    "    grouped = df.groupby(['review_id', 'review_number'])\n",
    "    \n",
    "    for (review_id, review_number), group in grouped:\n",
    "        prompt = generate_prompt(group)\n",
    "        decision, cot_reasoning = make_api_call(prompt)\n",
    "        \n",
    "        df.loc[(df['review_id'] == review_id) & (df['review_number'] == review_number), 'Decision'] = decision\n",
    "        df.loc[(df['review_id'] == review_id) & (df['review_number'] == review_number), 'CoT_Reasoning'] = cot_reasoning\n",
    "        time.sleep(15)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/llama-datasets/conviction_split_dataset_part_4.csv')\n",
    "annotated_df = annotate_dataset(df)\n",
    "annotated_df.to_csv('/kaggle/working/LLama_dataset_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5748518,
     "sourceId": 9472883,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5777208,
     "sourceId": 9494455,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5798533,
     "sourceId": 9523099,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5838959,
     "sourceId": 9577577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1590.219877,
   "end_time": "2024-10-11T09:42:34.275968",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-11T09:16:04.056091",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
